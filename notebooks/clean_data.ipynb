{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0212366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# create interactive plots\n",
    "import plotly.express as px \n",
    "# numeric calculations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b164cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhony\\AppData\\Local\\Temp\\ipykernel_25584\\2274232805.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_table(\"../data/flickr_dataset.csv\", sep=\",\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "long",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tags",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "date_taken_minute",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_taken_hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_taken_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_taken_month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_taken_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_upload_minute",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "date_upload_hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_upload_day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_upload_month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date_upload_year",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d896e512-36f1-4d6e-ba37-f23b37123a44",
       "rows": [
        [
         "0",
         "4395181099.0",
         "30624617@N03",
         "45.754858",
         "4.82171",
         "chair,lyon,rhône,chaise,rhônealpes",
         "Chaises avec vue",
         "11.0",
         "15.0",
         "28.0",
         "2.0",
         "2010.0",
         "23",
         "20.0",
         "28.0",
         "2.0",
         "2010.0"
        ],
        [
         "1",
         "4394748717.0",
         "35853470@N00",
         "45.75327",
         "4.862953",
         null,
         null,
         "51.0",
         "17.0",
         "28.0",
         "2.0",
         "2010.0",
         "52",
         "17.0",
         "28.0",
         "2.0",
         "2010.0"
        ],
        [
         "2",
         "4394694699.0",
         "11817998@N05",
         "45.760655",
         "4.846564",
         "365,iphone",
         "59/365 - R46 V103 B163",
         "29.0",
         "17.0",
         "28.0",
         "2.0",
         "2010.0",
         "33",
         "17.0",
         "28.0",
         "2.0",
         "2010.0"
        ],
        [
         "3",
         "4394803790.0",
         "11545749@N06",
         "45.784",
         "4.874072",
         "nin,nineinchnails,gift,screening,toiou,avott",
         "2010-01-29 Toiou Avott Lyon",
         "15.0",
         "20.0",
         "28.0",
         "1.0",
         "2010.0",
         "38",
         "12.0",
         "28.0",
         "2.0",
         "2010.0"
        ],
        [
         "4",
         "4394803554.0",
         "11545749@N06",
         "45.784",
         "4.874072",
         "lyon,nin,nineinchnails,gift,screening,toiou,avott",
         "2010-01-28 Toiou Avott Lyon",
         "10.0",
         "20.0",
         "28.0",
         "1.0",
         "2010.0",
         "38",
         "12.0",
         "28.0",
         "2.0",
         "2010.0"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.395181e+09</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.394749e+09</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>52</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.394695e+09</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>33</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.394804e+09</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.394804e+09</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id          user        lat      long  \\\n",
       "0  4.395181e+09  30624617@N03  45.754858  4.821710   \n",
       "1  4.394749e+09  35853470@N00  45.753270  4.862953   \n",
       "2  4.394695e+09  11817998@N05  45.760655  4.846564   \n",
       "3  4.394804e+09  11545749@N06  45.784000  4.874072   \n",
       "4  4.394804e+09  11545749@N06  45.784000  4.874072   \n",
       "\n",
       "                                                tags  \\\n",
       "0                 chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                NaN   \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "\n",
       "                         title  date_taken_minute  date_taken_hour  \\\n",
       "0             Chaises avec vue               11.0             15.0   \n",
       "1                          NaN               51.0             17.0   \n",
       "2       59/365 - R46 V103 B163               29.0             17.0   \n",
       "3  2010-01-29 Toiou Avott Lyon               15.0             20.0   \n",
       "4  2010-01-28 Toiou Avott Lyon               10.0             20.0   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
       "0            28.0               2.0           2010.0                 23   \n",
       "1            28.0               2.0           2010.0                 52   \n",
       "2            28.0               2.0           2010.0                 33   \n",
       "3            28.0               1.0           2010.0                 38   \n",
       "4            28.0               1.0           2010.0                 38   \n",
       "\n",
       "   date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \n",
       "0              20.0             28.0                2.0            2010.0  \n",
       "1              17.0             28.0                2.0            2010.0  \n",
       "2              17.0             28.0                2.0            2010.0  \n",
       "3              12.0             28.0                2.0            2010.0  \n",
       "4              12.0             28.0                2.0            2010.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"../data/flickr_dataset.csv\", sep=\",\")\n",
    "# show first 5 rows of the dataframe\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1140be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 420195 entries, 0 to 420194\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  420194 non-null  float64\n",
      " 1   user                420194 non-null  object \n",
      " 2   lat                 420194 non-null  float64\n",
      " 3   long                420194 non-null  float64\n",
      " 4   tags                316703 non-null  object \n",
      " 5   title               381864 non-null  object \n",
      " 6   date_taken_minute   420173 non-null  float64\n",
      " 7   date_taken_hour     420192 non-null  float64\n",
      " 8   date_taken_day      420192 non-null  float64\n",
      " 9   date_taken_month    420192 non-null  float64\n",
      " 10  date_taken_year     420194 non-null  float64\n",
      " 11  date_upload_minute  420102 non-null  object \n",
      " 12  date_upload_hour    420190 non-null  float64\n",
      " 13  date_upload_day     420192 non-null  float64\n",
      " 14  date_upload_month   420190 non-null  float64\n",
      " 15  date_upload_year    420193 non-null  float64\n",
      "dtypes: float64(12), object(4)\n",
      "memory usage: 51.3+ MB\n"
     ]
    }
   ],
   "source": [
    "len(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b60a5ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0f206fd0-7502-4e34-a3c8-253f6693fc37",
       "rows": [
        [
         "id",
         "1"
        ],
        [
         "user",
         "1"
        ],
        [
         "lat",
         "1"
        ],
        [
         "long",
         "1"
        ],
        [
         "tags",
         "103492"
        ],
        [
         "title",
         "38331"
        ],
        [
         "date_taken_minute",
         "22"
        ],
        [
         "date_taken_hour",
         "3"
        ],
        [
         "date_taken_day",
         "3"
        ],
        [
         "date_taken_month",
         "3"
        ],
        [
         "date_taken_year",
         "1"
        ],
        [
         "date_upload_minute",
         "93"
        ],
        [
         "date_upload_hour",
         "5"
        ],
        [
         "date_upload_day",
         "3"
        ],
        [
         "date_upload_month",
         "5"
        ],
        [
         "date_upload_year",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 16
       }
      },
      "text/plain": [
       "id                         1\n",
       "user                       1\n",
       "lat                        1\n",
       "long                       1\n",
       "tags                  103492\n",
       "title                  38331\n",
       "date_taken_minute         22\n",
       "date_taken_hour            3\n",
       "date_taken_day             3\n",
       "date_taken_month           3\n",
       "date_taken_year            1\n",
       "date_upload_minute        93\n",
       "date_upload_hour           5\n",
       "date_upload_day            3\n",
       "date_upload_month          5\n",
       "date_upload_year           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd1fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 420195\n",
      "Rows with missing values in relevant columns: 118297\n",
      "\n",
      "Missing values per relevant column:\n",
      "id                         1\n",
      "user                       1\n",
      "lat                        1\n",
      "long                       1\n",
      "tags                  103492\n",
      "title                  38331\n",
      "date_taken_minute         22\n",
      "date_taken_hour            3\n",
      "date_taken_day             3\n",
      "date_taken_month           3\n",
      "date_taken_year            1\n",
      "date_upload_minute        93\n",
      "date_upload_hour           5\n",
      "date_upload_day            3\n",
      "date_upload_month          5\n",
      "date_upload_year           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values only in relevant columns (excluding Unnamed)\n",
    "relevant_cols = data.columns[:16]  # First 16 columns\n",
    "missing_values_relevant = data[data[relevant_cols].isna().any(axis=1)]\n",
    "print(f\"Total rows: {len(data)}\")\n",
    "print(f\"Rows with missing values in relevant columns: {len(missing_values_relevant)}\")\n",
    "\n",
    "# Sum of missing values per relevant column\n",
    "print(\"\\nMissing values per relevant column:\")\n",
    "print(data[relevant_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9313ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 420195\n",
      "After removing duplicates: 189386\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in relevant columns\n",
    "data[relevant_cols].duplicated().sum()\n",
    "# remove duplicates\n",
    "data_without_duplicates = data[relevant_cols].drop_duplicates(keep='first')\n",
    "# show the stats\n",
    "print(f\"Initial: {len(data)}\")\n",
    "print(f\"After removing duplicates: {len(data_without_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bef9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to remove leading spaces\n",
    "data_without_duplicates.rename(columns={\n",
    "    'id': 'id',\n",
    "    ' user': 'user',\n",
    "    ' lat': 'lat',\n",
    "    ' long': 'long',\n",
    "    ' tags': 'tags',\n",
    "    ' title': 'title',\n",
    "    ' date_taken_minute': 'date_taken_minute',\n",
    "    ' date_taken_hour': 'date_taken_hour',\n",
    "    ' date_taken_day': 'date_taken_day',\n",
    "    ' date_taken_month': 'date_taken_month',  \n",
    "    ' date_taken_year': 'date_taken_year',\n",
    "    ' date_upload_minute': 'date_upload_minute',\n",
    "    ' date_upload_hour': 'date_upload_hour',\n",
    "    ' date_upload_day': 'date_upload_day',\n",
    "    ' date_upload_month': 'date_upload_month',\n",
    "    ' date_upload_year': 'date_upload_year'\n",
    "}, inplace=True)\n",
    "\n",
    "# Update relevant_cols to the new column names\n",
    "relevant_cols = ['id', 'user', 'lat', 'long', 'tags', 'title', 'date_taken_minute', 'date_taken_hour', 'date_taken_day', 'date_taken_month', 'date_taken_year', 'date_upload_minute', 'date_upload_hour', 'date_upload_day', 'date_upload_month', 'date_upload_year']\n",
    "# Export to CSV\n",
    "data_without_duplicates[relevant_cols].to_csv('../data/data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd890123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhony\\AppData\\Local\\Temp\\ipykernel_25584\\473674963.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('../data/data_cleaned.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189386\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "data_cleaned = pd.read_csv('../data/data_cleaned.csv')\n",
    "print(len(data_cleaned))\n",
    "\n",
    "# Define stop words to remove from titles\n",
    "stop_words = [\n",
    "    'is', 'the', 'a', 'an', 'est', 'le', 'la', 'un', 'une', 'les', 'des', 'du', 'de', 'à', 'au', 'aux',\n",
    "    'photo', 'picture', 'image', 'pic', 'img', 'shot', 'view', 'scene', 'l\\'', 'd\\'', 'of', 'and', 'or', 'but',\n",
    "    'in', 'on', 'at', 'to', 'for', 'with', 'by', 'from', 'as', 'into', 'through', 'during', 'before', 'after',\n",
    "    'above', 'below', 'between', 'among', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',\n",
    "    '-', '--', '—', '.', ',', '!', '?', ':', ';', '\"', \"'\", '(', ')', '[', ']', '{', '}', '...'\n",
    "]\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_title(title):\n",
    "    if pd.isna(title):\n",
    "        return ''\n",
    "    # Convert to lowercase\n",
    "    title = str(title).lower()\n",
    "    # Remove punctuation and special characters\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    # Split into words\n",
    "    words = title.split()\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join back\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply cleaning to title column\n",
    "data_cleaned['title'] = data_cleaned['title'].apply(clean_title)\n",
    "\n",
    "# Save to new CSV\n",
    "data_cleaned.to_csv('../data/data_cleaned_titles.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows based on 'id': 21290\n",
      "Number of duplicate rows based on ['id','user']: 21290\n",
      "\n",
      "Examples of duplicates in 'id':\n",
      "                  id           user        lat      long  \\\n",
      "16603   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "21127   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "42833   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "45655   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "47958   8.150613e+09   58993764@N06  45.761180  4.831458   \n",
      "...              ...            ...        ...       ...   \n",
      "189381  4.440233e+10   90493526@N00  45.758316  4.825197   \n",
      "189382  4.421075e+10  144146684@N04  45.762635  4.837299   \n",
      "189383  4.512236e+10   95450872@N03  45.763657  4.836012   \n",
      "189384  4.507335e+10   95450872@N03  45.763657  4.836012   \n",
      "189385  4.512209e+10   61949122@N06  45.758181  4.831967   \n",
      "\n",
      "                                                     tags  \\\n",
      "16603                           lundimatin,lyondefi38nuit   \n",
      "21127                           lundimatin,lyondefi38nuit   \n",
      "42833   city,blackandwhite,france,water,river,french,c...   \n",
      "45655   city,blackandwhite,france,water,river,french,c...   \n",
      "47958   square,squareformat,hefe,iphoneography,instagr...   \n",
      "...                                                   ...   \n",
      "189381  europe,france,lyon,croixrousse,streetart,wheat...   \n",
      "189382                                                NaN   \n",
      "189383  auvergnerhônealpes,rhône,lyonnais,valléedurhôn...   \n",
      "189384  auvergnerhônealpes,rhône,lyonnais,valléedurhôn...   \n",
      "189385  ngc,lyon,paysage,landscape,ville,urbain,town,tour   \n",
      "\n",
      "                                   title  date_taken_minute  date_taken_hour  \\\n",
      "16603    lundi matin comme tout autre 25                6.0             21.0   \n",
      "21127       lundi matin comme tout autre               25.0              6.0   \n",
      "42833                             bridge             2012.0             38.0   \n",
      "45655                       bridge rhône             2012.0             38.0   \n",
      "47958                        newlyonnais             2012.0             22.0   \n",
      "...                                  ...                ...              ...   \n",
      "189381  pasted paper big ben lyon france               18.0             17.0   \n",
      "189382                       white blood               36.0             16.0   \n",
      "189383         lyon porte passage largue               48.0             19.0   \n",
      "189384               lyon passage largue               48.0             19.0   \n",
      "189385         tour peut en cacher autre               15.0             14.0   \n",
      "\n",
      "        date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
      "16603              2.0            2011.0             11.0               15.0   \n",
      "21127             21.0               2.0           2011.0               11.0   \n",
      "42833             11.0               7.0           2012.0                NaN   \n",
      "45655             11.0               7.0           2012.0                NaN   \n",
      "47958              7.0               3.0           2012.0                NaN   \n",
      "...                ...               ...              ...                ...   \n",
      "189381            30.0               9.0           2018.0               11.0   \n",
      "189382             5.0              10.0           2018.0               41.0   \n",
      "189383            27.0               9.0           2018.0               40.0   \n",
      "189384            27.0               9.0           2018.0               29.0   \n",
      "189385            28.0               9.0           2018.0               21.0   \n",
      "\n",
      "        date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \n",
      "16603               21.0              2.0             2011.0               NaN  \n",
      "21127               15.0             21.0                2.0            2011.0  \n",
      "42833                5.0             18.0               16.0            2012.0  \n",
      "45655                5.0             18.0               16.0            2012.0  \n",
      "47958               22.0             15.0                3.0            2012.0  \n",
      "...                  ...              ...                ...               ...  \n",
      "189381              23.0              5.0               10.0            2018.0  \n",
      "189382              22.0              5.0               10.0            2018.0  \n",
      "189383              22.0              5.0               10.0            2018.0  \n",
      "189384              22.0              5.0               10.0            2018.0  \n",
      "189385              22.0              5.0               10.0            2018.0  \n",
      "\n",
      "[42575 rows x 16 columns]\n",
      "\n",
      "Examples of duplicates in ['id', 'user']:\n",
      "                  id           user        lat      long  \\\n",
      "16603   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "21127   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "42833   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "45655   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "47958   8.150613e+09   58993764@N06  45.761180  4.831458   \n",
      "...              ...            ...        ...       ...   \n",
      "189381  4.440233e+10   90493526@N00  45.758316  4.825197   \n",
      "189382  4.421075e+10  144146684@N04  45.762635  4.837299   \n",
      "189383  4.512236e+10   95450872@N03  45.763657  4.836012   \n",
      "189384  4.507335e+10   95450872@N03  45.763657  4.836012   \n",
      "189385  4.512209e+10   61949122@N06  45.758181  4.831967   \n",
      "\n",
      "                                                     tags  \\\n",
      "16603                           lundimatin,lyondefi38nuit   \n",
      "21127                           lundimatin,lyondefi38nuit   \n",
      "42833   city,blackandwhite,france,water,river,french,c...   \n",
      "45655   city,blackandwhite,france,water,river,french,c...   \n",
      "47958   square,squareformat,hefe,iphoneography,instagr...   \n",
      "...                                                   ...   \n",
      "189381  europe,france,lyon,croixrousse,streetart,wheat...   \n",
      "189382                                                NaN   \n",
      "189383  auvergnerhônealpes,rhône,lyonnais,valléedurhôn...   \n",
      "189384  auvergnerhônealpes,rhône,lyonnais,valléedurhôn...   \n",
      "189385  ngc,lyon,paysage,landscape,ville,urbain,town,tour   \n",
      "\n",
      "                                   title  date_taken_minute  date_taken_hour  \\\n",
      "16603    lundi matin comme tout autre 25                6.0             21.0   \n",
      "21127       lundi matin comme tout autre               25.0              6.0   \n",
      "42833                             bridge             2012.0             38.0   \n",
      "45655                       bridge rhône             2012.0             38.0   \n",
      "47958                        newlyonnais             2012.0             22.0   \n",
      "...                                  ...                ...              ...   \n",
      "189381  pasted paper big ben lyon france               18.0             17.0   \n",
      "189382                       white blood               36.0             16.0   \n",
      "189383         lyon porte passage largue               48.0             19.0   \n",
      "189384               lyon passage largue               48.0             19.0   \n",
      "189385         tour peut en cacher autre               15.0             14.0   \n",
      "\n",
      "        date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
      "16603              2.0            2011.0             11.0               15.0   \n",
      "21127             21.0               2.0           2011.0               11.0   \n",
      "42833             11.0               7.0           2012.0                NaN   \n",
      "45655             11.0               7.0           2012.0                NaN   \n",
      "47958              7.0               3.0           2012.0                NaN   \n",
      "...                ...               ...              ...                ...   \n",
      "189381            30.0               9.0           2018.0               11.0   \n",
      "189382             5.0              10.0           2018.0               41.0   \n",
      "189383            27.0               9.0           2018.0               40.0   \n",
      "189384            27.0               9.0           2018.0               29.0   \n",
      "189385            28.0               9.0           2018.0               21.0   \n",
      "\n",
      "        date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \n",
      "16603               21.0              2.0             2011.0               NaN  \n",
      "21127               15.0             21.0                2.0            2011.0  \n",
      "42833                5.0             18.0               16.0            2012.0  \n",
      "45655                5.0             18.0               16.0            2012.0  \n",
      "47958               22.0             15.0                3.0            2012.0  \n",
      "...                  ...              ...                ...               ...  \n",
      "189381              23.0              5.0               10.0            2018.0  \n",
      "189382              22.0              5.0               10.0            2018.0  \n",
      "189383              22.0              5.0               10.0            2018.0  \n",
      "189384              22.0              5.0               10.0            2018.0  \n",
      "189385              22.0              5.0               10.0            2018.0  \n",
      "\n",
      "[42575 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'id' column\n",
    "duplicates_id = data_cleaned.duplicated(subset=['id']).sum()\n",
    "print(f\"Number of duplicate rows based on 'id': {duplicates_id}\")\n",
    "\n",
    "# Check for duplicates in ['id', 'user']\n",
    "duplicates_id_user = data_cleaned.duplicated(subset=['id','user']).sum()\n",
    "print(f\"Number of duplicate rows based on ['id','user']: {duplicates_id_user}\")\n",
    "\n",
    "# Show some examples of duplicates if any\n",
    "if duplicates_id > 0:\n",
    "    print(\"\\nExamples of duplicates in 'id':\")\n",
    "    print(data_cleaned[data_cleaned.duplicated(subset=['id'], keep=False)])\n",
    "\n",
    "if duplicates_id_user > 0:\n",
    "    print(\"\\nExamples of duplicates in ['id', 'user']:\")\n",
    "    print(data_cleaned[data_cleaned.duplicated(subset=['id', 'user'], keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fd42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping duplicates based on ['id', 'user']: 168096\n",
      "After dropping rows with empty 'lat' or 'long': 168095\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on 'id' and 'user'\n",
    "data_cleaned = data_cleaned.drop_duplicates(subset=['id', 'user'], keep='first')\n",
    "print(f\"After dropping duplicates based on ['id', 'user']: {len(data_cleaned)}\")\n",
    "\n",
    "# Drop empty lat and long\n",
    "data_cleaned = data_cleaned.dropna(subset=['lat', 'long'])\n",
    "print(f\"After dropping rows with empty 'lat' or 'long': {len(data_cleaned)}\")\n",
    "\n",
    "# Save the cleaned data\n",
    "data_cleaned.to_csv('../data/data_cleaned_titles.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
