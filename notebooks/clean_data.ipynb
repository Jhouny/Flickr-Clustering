{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0212366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# create interactive plots\n",
    "import plotly.express as px \n",
    "# numeric calculations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b164cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12888\\2274232805.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_table(\"../data/flickr_dataset.csv\", sep=\",\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.395181e+09</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.394749e+09</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>52</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.394695e+09</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>33</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.394804e+09</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.394804e+09</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id          user        lat      long  \\\n",
       "0  4.395181e+09  30624617@N03  45.754858  4.821710   \n",
       "1  4.394749e+09  35853470@N00  45.753270  4.862953   \n",
       "2  4.394695e+09  11817998@N05  45.760655  4.846564   \n",
       "3  4.394804e+09  11545749@N06  45.784000  4.874072   \n",
       "4  4.394804e+09  11545749@N06  45.784000  4.874072   \n",
       "\n",
       "                                                tags  \\\n",
       "0                 chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                NaN   \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "\n",
       "                         title  date_taken_minute  date_taken_hour  \\\n",
       "0             Chaises avec vue               11.0             15.0   \n",
       "1                          NaN               51.0             17.0   \n",
       "2       59/365 - R46 V103 B163               29.0             17.0   \n",
       "3  2010-01-29 Toiou Avott Lyon               15.0             20.0   \n",
       "4  2010-01-28 Toiou Avott Lyon               10.0             20.0   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
       "0            28.0               2.0           2010.0                 23   \n",
       "1            28.0               2.0           2010.0                 52   \n",
       "2            28.0               2.0           2010.0                 33   \n",
       "3            28.0               1.0           2010.0                 38   \n",
       "4            28.0               1.0           2010.0                 38   \n",
       "\n",
       "   date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \n",
       "0              20.0             28.0                2.0            2010.0  \n",
       "1              17.0             28.0                2.0            2010.0  \n",
       "2              17.0             28.0                2.0            2010.0  \n",
       "3              12.0             28.0                2.0            2010.0  \n",
       "4              12.0             28.0                2.0            2010.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"../data/flickr_dataset.csv\", sep=\",\")\n",
    "# show first 5 rows of the dataframe\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1140be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 420195 entries, 0 to 420194\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  420194 non-null  float64\n",
      " 1   user                420194 non-null  object \n",
      " 2   lat                 420194 non-null  float64\n",
      " 3   long                420194 non-null  float64\n",
      " 4   tags                316703 non-null  object \n",
      " 5   title               381864 non-null  object \n",
      " 6   date_taken_minute   420173 non-null  float64\n",
      " 7   date_taken_hour     420192 non-null  float64\n",
      " 8   date_taken_day      420192 non-null  float64\n",
      " 9   date_taken_month    420192 non-null  float64\n",
      " 10  date_taken_year     420194 non-null  float64\n",
      " 11  date_upload_minute  420102 non-null  object \n",
      " 12  date_upload_hour    420190 non-null  float64\n",
      " 13  date_upload_day     420192 non-null  float64\n",
      " 14  date_upload_month   420190 non-null  float64\n",
      " 15  date_upload_year    420193 non-null  float64\n",
      "dtypes: float64(12), object(4)\n",
      "memory usage: 51.3+ MB\n"
     ]
    }
   ],
   "source": [
    "len(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60a5ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         1\n",
       "user                       1\n",
       "lat                        1\n",
       "long                       1\n",
       "tags                  103492\n",
       "title                  38331\n",
       "date_taken_minute         22\n",
       "date_taken_hour            3\n",
       "date_taken_day             3\n",
       "date_taken_month           3\n",
       "date_taken_year            1\n",
       "date_upload_minute        93\n",
       "date_upload_hour           5\n",
       "date_upload_day            3\n",
       "date_upload_month          5\n",
       "date_upload_year           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd1fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 420195\n",
      "Rows with missing values in relevant columns: 118297\n",
      "\n",
      "Missing values per relevant column:\n",
      "id                         1\n",
      "user                       1\n",
      "lat                        1\n",
      "long                       1\n",
      "tags                  103492\n",
      "title                  38331\n",
      "date_taken_minute         22\n",
      "date_taken_hour            3\n",
      "date_taken_day             3\n",
      "date_taken_month           3\n",
      "date_taken_year            1\n",
      "date_upload_minute        93\n",
      "date_upload_hour           5\n",
      "date_upload_day            3\n",
      "date_upload_month          5\n",
      "date_upload_year           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values only in relevant columns (excluding Unnamed)\n",
    "relevant_cols = data.columns[:16]  # First 16 columns\n",
    "missing_values_relevant = data[data[relevant_cols].isna().any(axis=1)]\n",
    "print(f\"Total rows: {len(data)}\")\n",
    "print(f\"Rows with missing values in relevant columns: {len(missing_values_relevant)}\")\n",
    "\n",
    "# Sum of missing values per relevant column\n",
    "print(\"\\nMissing values per relevant column:\")\n",
    "print(data[relevant_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b9313ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 420195\n",
      "After removing duplicates: 189386\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in relevant columns\n",
    "data[relevant_cols].duplicated().sum()\n",
    "# remove duplicates\n",
    "data_without_duplicates = data[relevant_cols].drop_duplicates(keep='first')\n",
    "# show the stats\n",
    "print(f\"Initial: {len(data)}\")\n",
    "print(f\"After removing duplicates: {len(data_without_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bef9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to remove leading spaces\n",
    "data_without_duplicates.rename(columns={\n",
    "    'id': 'id',\n",
    "    ' user': 'user',\n",
    "    ' lat': 'lat',\n",
    "    ' long': 'long',\n",
    "    ' tags': 'tags',\n",
    "    ' title': 'title',\n",
    "    ' date_taken_minute': 'date_taken_minute',\n",
    "    ' date_taken_hour': 'date_taken_hour',\n",
    "    ' date_taken_day': 'date_taken_day',\n",
    "    ' date_taken_month': 'date_taken_month',  \n",
    "    ' date_taken_year': 'date_taken_year',\n",
    "    ' date_upload_minute': 'date_upload_minute',\n",
    "    ' date_upload_hour': 'date_upload_hour',\n",
    "    ' date_upload_day': 'date_upload_day',\n",
    "    ' date_upload_month': 'date_upload_month',\n",
    "    ' date_upload_year': 'date_upload_year'\n",
    "}, inplace=True)\n",
    "\n",
    "# Update relevant_cols to the new column names\n",
    "relevant_cols = ['id', 'user', 'lat', 'long', 'tags', 'title', 'date_taken_minute', 'date_taken_hour', 'date_taken_day', 'date_taken_month', 'date_taken_year', 'date_upload_minute', 'date_upload_hour', 'date_upload_day', 'date_upload_month', 'date_upload_year']\n",
    "# Export to CSV\n",
    "data_without_duplicates[relevant_cols].to_csv('../data/data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd890123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12888\\1553274970.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_cleaned = pd.read_csv('../data/data_cleaned.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189386\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "data_cleaned = pd.read_csv('../data/data_cleaned.csv')\n",
    "print(len(data_cleaned))\n",
    "\n",
    "# Define stop words to remove from titles\n",
    "stop_words = [\n",
    "    'is', 'the', 'a', 'an', 'est', 'le', 'la', 'un', 'une', 'les', 'des', 'du', 'de', 'à', 'au', 'aux',\n",
    "    'photo', 'picture', 'image', 'pic', 'img', 'shot', 'view', 'scene', 'france', 'lyon', 'l\\'', 'd\\'', 'of', 'and', 'or', 'but',\n",
    "    'in', 'on', 'at', 'to', 'for', 'with', 'by', 'from', 'as', 'into', 'through', 'during', 'before', 'after',\n",
    "    'above', 'below', 'between', 'among', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'insta', 'instagram','lione','europe','auvergne','auvergnerhonealpes'\n",
    "    '-', '--', '—', '.', ',', '!', '?', ':', ';', '\"', \"'\", '(', ')', '[', ']', '{', '}', '...'\n",
    "]\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    return ''.join(\n",
    "        char for char in unicodedata.normalize('NFKD', text)\n",
    "        if not unicodedata.combining(char)\n",
    "    )\n",
    "\n",
    "def clean_title(title):\n",
    "    if pd.isna(title):\n",
    "        return ''\n",
    "    # Convert to lowercase\n",
    "    title = str(title).lower()\n",
    "    title = remove_accents(title)\n",
    "    # Remove punctuation and special characters\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    # Split into words\n",
    "    words = title.split()\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join back\n",
    "    return ' '.join(words)\n",
    "\n",
    "def clean_tags(tags):\n",
    "    if pd.isna(tags):\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tags = str(tags).lower()\n",
    "\n",
    "    tags = remove_accents(tags)\n",
    "    # Remplacer les virgules par des espaces\n",
    "    tags = tags.replace(',', ' ')\n",
    "    \n",
    "    # Supprimer ponctuation et caractères spéciaux\n",
    "    tags = re.sub(r'[^\\w\\s]', '', tags)\n",
    "    \n",
    "    # Découper en mots\n",
    "    words = tags.split()\n",
    "    \n",
    "    # Supprimer les stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Recomposer\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply cleaning to title column\n",
    "data_cleaned['title'] = data_cleaned['title'].apply(clean_title)\n",
    "\n",
    "# Apply cleaning to tags column\n",
    "data_cleaned['tags'] = data_cleaned['tags'].apply(clean_tags)\n",
    "\n",
    "# Save to new CSV\n",
    "data_cleaned.to_csv('../data/data_cleaned_titles.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205b3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows based on 'id': 21290\n",
      "Number of duplicate rows based on ['id','user']: 21290\n",
      "\n",
      "Examples of duplicates in 'id':\n",
      "                  id           user        lat      long  \\\n",
      "16603   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "21127   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "42833   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "45655   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "47958   8.150613e+09   58993764@N06  45.761180  4.831458   \n",
      "...              ...            ...        ...       ...   \n",
      "189381  4.440233e+10   90493526@N00  45.758316  4.825197   \n",
      "189382  4.421075e+10  144146684@N04  45.762635  4.837299   \n",
      "189383  4.512236e+10   95450872@N03  45.763657  4.836012   \n",
      "189384  4.507335e+10   95450872@N03  45.763657  4.836012   \n",
      "189385  4.512209e+10   61949122@N06  45.758181  4.831967   \n",
      "\n",
      "                                                     tags  \\\n",
      "16603                           lundimatin lyondefi38nuit   \n",
      "21127                           lundimatin lyondefi38nuit   \n",
      "42833   city blackandwhite water river french concrete...   \n",
      "45655   city blackandwhite water river french concrete...   \n",
      "47958   square squareformat hefe iphoneography instagr...   \n",
      "...                                                   ...   \n",
      "189381  croixrousse streetart wheatpaste wheatpaper co...   \n",
      "189382                                                      \n",
      "189383  auvergnerhonealpes rhone lyonnais valleedurhon...   \n",
      "189384  auvergnerhonealpes rhone lyonnais valleedurhon...   \n",
      "189385       ngc paysage landscape ville urbain town tour   \n",
      "\n",
      "                                  title  date_taken_minute  date_taken_hour  \\\n",
      "16603   lundi matin comme tout autre 25                6.0             21.0   \n",
      "21127      lundi matin comme tout autre               25.0              6.0   \n",
      "42833                            bridge             2012.0             38.0   \n",
      "45655                      bridge rhone             2012.0             38.0   \n",
      "47958                       newlyonnais             2012.0             22.0   \n",
      "...                                 ...                ...              ...   \n",
      "189381             pasted paper big ben               18.0             17.0   \n",
      "189382                      white blood               36.0             16.0   \n",
      "189383             porte passage largue               48.0             19.0   \n",
      "189384                   passage largue               48.0             19.0   \n",
      "189385        tour peut en cacher autre               15.0             14.0   \n",
      "\n",
      "        date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
      "16603              2.0            2011.0             11.0               15.0   \n",
      "21127             21.0               2.0           2011.0               11.0   \n",
      "42833             11.0               7.0           2012.0                NaN   \n",
      "45655             11.0               7.0           2012.0                NaN   \n",
      "47958              7.0               3.0           2012.0                NaN   \n",
      "...                ...               ...              ...                ...   \n",
      "189381            30.0               9.0           2018.0               11.0   \n",
      "189382             5.0              10.0           2018.0               41.0   \n",
      "189383            27.0               9.0           2018.0               40.0   \n",
      "189384            27.0               9.0           2018.0               29.0   \n",
      "189385            28.0               9.0           2018.0               21.0   \n",
      "\n",
      "        date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \n",
      "16603               21.0              2.0             2011.0               NaN  \n",
      "21127               15.0             21.0                2.0            2011.0  \n",
      "42833                5.0             18.0               16.0            2012.0  \n",
      "45655                5.0             18.0               16.0            2012.0  \n",
      "47958               22.0             15.0                3.0            2012.0  \n",
      "...                  ...              ...                ...               ...  \n",
      "189381              23.0              5.0               10.0            2018.0  \n",
      "189382              22.0              5.0               10.0            2018.0  \n",
      "189383              22.0              5.0               10.0            2018.0  \n",
      "189384              22.0              5.0               10.0            2018.0  \n",
      "189385              22.0              5.0               10.0            2018.0  \n",
      "\n",
      "[42575 rows x 16 columns]\n",
      "\n",
      "Examples of duplicates in ['id', 'user']:\n",
      "                  id           user        lat      long  \\\n",
      "16603   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "21127   5.464485e+09   35635047@N03  45.765517  4.766510   \n",
      "42833   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "45655   7.583546e+09   37290448@N04  45.772827  4.841065   \n",
      "47958   8.150613e+09   58993764@N06  45.761180  4.831458   \n",
      "...              ...            ...        ...       ...   \n",
      "189381  4.440233e+10   90493526@N00  45.758316  4.825197   \n",
      "189382  4.421075e+10  144146684@N04  45.762635  4.837299   \n",
      "189383  4.512236e+10   95450872@N03  45.763657  4.836012   \n",
      "189384  4.507335e+10   95450872@N03  45.763657  4.836012   \n",
      "189385  4.512209e+10   61949122@N06  45.758181  4.831967   \n",
      "\n",
      "                                                     tags  \\\n",
      "16603                           lundimatin lyondefi38nuit   \n",
      "21127                           lundimatin lyondefi38nuit   \n",
      "42833   city blackandwhite water river french concrete...   \n",
      "45655   city blackandwhite water river french concrete...   \n",
      "47958   square squareformat hefe iphoneography instagr...   \n",
      "...                                                   ...   \n",
      "189381  croixrousse streetart wheatpaste wheatpaper co...   \n",
      "189382                                                      \n",
      "189383  auvergnerhonealpes rhone lyonnais valleedurhon...   \n",
      "189384  auvergnerhonealpes rhone lyonnais valleedurhon...   \n",
      "189385       ngc paysage landscape ville urbain town tour   \n",
      "\n",
      "                                  title  date_taken_minute  date_taken_hour  \\\n",
      "16603   lundi matin comme tout autre 25                6.0             21.0   \n",
      "21127      lundi matin comme tout autre               25.0              6.0   \n",
      "42833                            bridge             2012.0             38.0   \n",
      "45655                      bridge rhone             2012.0             38.0   \n",
      "47958                       newlyonnais             2012.0             22.0   \n",
      "...                                 ...                ...              ...   \n",
      "189381             pasted paper big ben               18.0             17.0   \n",
      "189382                      white blood               36.0             16.0   \n",
      "189383             porte passage largue               48.0             19.0   \n",
      "189384                   passage largue               48.0             19.0   \n",
      "189385        tour peut en cacher autre               15.0             14.0   \n",
      "\n",
      "        date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
      "16603              2.0            2011.0             11.0               15.0   \n",
      "21127             21.0               2.0           2011.0               11.0   \n",
      "42833             11.0               7.0           2012.0                NaN   \n",
      "45655             11.0               7.0           2012.0                NaN   \n",
      "47958              7.0               3.0           2012.0                NaN   \n",
      "...                ...               ...              ...                ...   \n",
      "189381            30.0               9.0           2018.0               11.0   \n",
      "189382             5.0              10.0           2018.0               41.0   \n",
      "189383            27.0               9.0           2018.0               40.0   \n",
      "189384            27.0               9.0           2018.0               29.0   \n",
      "189385            28.0               9.0           2018.0               21.0   \n",
      "\n",
      "        date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \n",
      "16603               21.0              2.0             2011.0               NaN  \n",
      "21127               15.0             21.0                2.0            2011.0  \n",
      "42833                5.0             18.0               16.0            2012.0  \n",
      "45655                5.0             18.0               16.0            2012.0  \n",
      "47958               22.0             15.0                3.0            2012.0  \n",
      "...                  ...              ...                ...               ...  \n",
      "189381              23.0              5.0               10.0            2018.0  \n",
      "189382              22.0              5.0               10.0            2018.0  \n",
      "189383              22.0              5.0               10.0            2018.0  \n",
      "189384              22.0              5.0               10.0            2018.0  \n",
      "189385              22.0              5.0               10.0            2018.0  \n",
      "\n",
      "[42575 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in 'id' column\n",
    "duplicates_id = data_cleaned.duplicated(subset=['id']).sum()\n",
    "print(f\"Number of duplicate rows based on 'id': {duplicates_id}\")\n",
    "\n",
    "# Check for duplicates in ['id', 'user']\n",
    "duplicates_id_user = data_cleaned.duplicated(subset=['id','user']).sum()\n",
    "print(f\"Number of duplicate rows based on ['id','user']: {duplicates_id_user}\")\n",
    "\n",
    "# Show some examples of duplicates if any\n",
    "if duplicates_id > 0:\n",
    "    print(\"\\nExamples of duplicates in 'id':\")\n",
    "    print(data_cleaned[data_cleaned.duplicated(subset=['id'], keep=False)])\n",
    "\n",
    "if duplicates_id_user > 0:\n",
    "    print(\"\\nExamples of duplicates in ['id', 'user']:\")\n",
    "    print(data_cleaned[data_cleaned.duplicated(subset=['id', 'user'], keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679fd42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping duplicates based on ['id', 'user']: 168096\n",
      "After dropping rows with empty 'lat' or 'long': 168095\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on 'id' and 'user'\n",
    "data_cleaned = data_cleaned.drop_duplicates(subset=['id', 'user'], keep='first')\n",
    "print(f\"After dropping duplicates based on ['id', 'user']: {len(data_cleaned)}\")\n",
    "\n",
    "# Drop empty lat and long\n",
    "data_cleaned = data_cleaned.dropna(subset=['lat', 'long'])\n",
    "print(f\"After dropping rows with empty 'lat' or 'long': {len(data_cleaned)}\")\n",
    "\n",
    "# Save the cleaned data\n",
    "data_cleaned.to_csv('../data/data_cleaned_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02842c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "651b846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "date_taken_minute [0-60]:\n",
      "18 valeurs non-numériques\n",
      "Exemples: [nan, nan, nan, nan, nan]\n",
      "25 valeurs en dehors de la plage [0, 60]\n",
      "     Min: 0.0, Max: 2019.0\n",
      "     Exemples des violations:\n",
      "       Ligne 35329: 2012.0\n",
      "       Ligne 41465: 2012.0\n",
      "       Ligne 41473: 2012.0\n",
      "       Ligne 42833: 2012.0\n",
      "       Ligne 43187: 2012.0\n",
      "\n",
      "date_taken_hour [0-24]:\n",
      "1 valeurs non-numériques\n",
      "Exemples: [nan]\n",
      "26 valeurs en dehors de la plage [0, 24]\n",
      "     Min: 0.0, Max: 57.0\n",
      "     Exemples des violations:\n",
      "       Ligne 35329: 29.0\n",
      "       Ligne 41473: 46.0\n",
      "       Ligne 42833: 38.0\n",
      "       Ligne 43187: 49.0\n",
      "       Ligne 44632: 44.0\n",
      "\n",
      "date_taken_day [1-31]:\n",
      "1 valeurs non-numériques\n",
      "Exemples: [nan]\n",
      "Toutes les valeurs sont dans la plage [1, 31]\n",
      "\n",
      "date_taken_month [1-12]:\n",
      "1 valeurs non-numériques\n",
      "Exemples: [nan]\n",
      "25 valeurs en dehors de la plage [1, 12]\n",
      "     Min: 1.0, Max: 2011.0\n",
      "     Exemples des violations:\n",
      "       Ligne 16603: 2011.0\n",
      "       Ligne 41473: 17.0\n",
      "       Ligne 44632: 27.0\n",
      "       Ligne 44903: 19.0\n",
      "       Ligne 49711: 31.0\n",
      "\n",
      "date_taken_year [1900-2026]:\n",
      "Toutes les valeurs sont numériques\n",
      "2 valeurs en dehors de la plage [1900, 2026]\n",
      "     Min: 11.0, Max: 2238.0\n",
      "     Exemples des violations:\n",
      "       Ligne 16603: 11.0\n",
      "       Ligne 44504: 2238.0\n",
      "\n",
      "date_upload_minute [0-60]:\n",
      "45 valeurs non-numériques\n",
      "Exemples: [nan, nan, nan, nan, nan]\n",
      "Toutes les valeurs sont dans la plage [0, 60]\n",
      "\n",
      "date_upload_hour [0-24]:\n",
      "2 valeurs non-numériques\n",
      "Exemples: [nan, nan]\n",
      "24 valeurs en dehors de la plage [0, 24]\n",
      "     Min: 0.0, Max: 54.0\n",
      "     Exemples des violations:\n",
      "       Ligne 35329: 47.0\n",
      "       Ligne 41465: 32.0\n",
      "       Ligne 41473: 46.0\n",
      "       Ligne 43187: 49.0\n",
      "       Ligne 44632: 44.0\n",
      "\n",
      "date_upload_day [1-31]:\n",
      "1 valeurs non-numériques\n",
      "Exemples: [nan]\n",
      "1 valeurs en dehors de la plage [1, 31]\n",
      "     Min: 0.0, Max: 31.0\n",
      "     Exemples des violations:\n",
      "       Ligne 120378: 0.0\n",
      "\n",
      "date_upload_month [1-12]:\n",
      "1 valeurs non-numériques\n",
      "Exemples: [nan]\n",
      "27 valeurs en dehors de la plage [1, 12]\n",
      "     Min: 1.0, Max: 2011.0\n",
      "     Exemples des violations:\n",
      "       Ligne 16603: 2011.0\n",
      "       Ligne 41465: 17.0\n",
      "       Ligne 41473: 17.0\n",
      "       Ligne 42833: 16.0\n",
      "       Ligne 44632: 27.0\n",
      "\n",
      "date_upload_year [1900-2026]:\n",
      "1 valeurs non-numériques\n",
      "Exemples: [nan]\n",
      "Toutes les valeurs sont dans la plage [1900, 2026]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Colonnes à vérifier\n",
    "date_columns = {\n",
    "    'date_taken_minute': (0, 60),\n",
    "    'date_taken_hour': (0, 24),\n",
    "    'date_taken_day': (1, 31),\n",
    "    'date_taken_month': (1, 12),\n",
    "    'date_taken_year': (1900, 2026),\n",
    "    'date_upload_minute': (0, 60),\n",
    "    'date_upload_hour': (0, 24),\n",
    "    'date_upload_day': (1, 31),\n",
    "    'date_upload_month': (1, 12),\n",
    "    'date_upload_year': (1900, 2026)\n",
    "}\n",
    "\n",
    "# Résultats globaux\n",
    "all_valid = True\n",
    "\n",
    "for col, (min_val, max_val) in date_columns.items():\n",
    "    if col not in data_cleaned.columns:\n",
    "        print(f\"\\n COLONNE MANQUANTE: {col}\")\n",
    "        all_valid = False\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{col} [{min_val}-{max_val}]:\")\n",
    "    \n",
    "    # Vérifier si ce sont des chiffres\n",
    "    numeric_vals = pd.to_numeric(data_cleaned[col], errors='coerce')\n",
    "    non_numeric = numeric_vals.isna().sum()\n",
    "    \n",
    "    if non_numeric > 0:\n",
    "        print(f\"{non_numeric} valeurs non-numériques\")\n",
    "        all_valid = False\n",
    "        invalid_indices = data_cleaned[numeric_vals.isna()].index\n",
    "        print(f\"Exemples: {list(data_cleaned.loc[invalid_indices, col].head())}\")\n",
    "    else:\n",
    "        print(f\"Toutes les valeurs sont numériques\")\n",
    "    \n",
    "    # Vérifier les plages\n",
    "    out_of_range = ((numeric_vals < min_val) | (numeric_vals > max_val)).sum()\n",
    "    \n",
    "    if out_of_range > 0:\n",
    "        print(f\"{out_of_range} valeurs en dehors de la plage [{min_val}, {max_val}]\")\n",
    "        all_valid = False\n",
    "        violations = (numeric_vals < min_val) | (numeric_vals > max_val)\n",
    "        violation_vals = numeric_vals[violations]\n",
    "        print(f\"     Min: {numeric_vals.min()}, Max: {numeric_vals.max()}\")\n",
    "        print(f\"     Exemples des violations:\")\n",
    "        for idx, val in violation_vals.head(5).items():\n",
    "            print(f\"       Ligne {idx}: {val}\")\n",
    "    else:\n",
    "        print(f\"Toutes les valeurs sont dans la plage [{min_val}, {max_val}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06bcce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VÉRIFICATION PAR LIGNE - GROUPES DE DATES\n",
      "\n",
      "Résultats:\n",
      "- Lignes avec TOUTES les dates invalides (taken ET upload): 0\n",
      "\n",
      "- Lignes avec 1 groupe complet invalide (soit taken SOIT upload): 0\n",
      "\n",
      "Résumé:\n",
      "- Total lignes avec au moins une date invalide: 0\n",
      "- Lignes valides complètement: 168095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"VÉRIFICATION PAR LIGNE - GROUPES DE DATES\")\n",
    "\n",
    "# Définir les groupes de dates\n",
    "taken_cols = ['date_taken_minute', 'date_taken_hour', 'date_taken_day', 'date_taken_month', 'date_taken_year']\n",
    "upload_cols = ['date_upload_minute', 'date_upload_hour', 'date_upload_day', 'date_upload_month', 'date_upload_year']\n",
    "\n",
    "# Plages de validation\n",
    "validation_ranges = {\n",
    "    'date_taken_minute': (0, 60), 'date_taken_hour': (0, 24), 'date_taken_day': (1, 31),\n",
    "    'date_taken_month': (1, 12), 'date_taken_year': (1900, 2026),\n",
    "    'date_upload_minute': (0, 60), 'date_upload_hour': (0, 24), 'date_upload_day': (1, 31),\n",
    "    'date_upload_month': (1, 12), 'date_upload_year': (1900, 2026)\n",
    "}\n",
    "\n",
    "# Fonction pour vérifier si une date est valide\n",
    "def is_date_valid(value, min_val, max_val):\n",
    "    try:\n",
    "        num_val = pd.to_numeric(value, errors='coerce')\n",
    "        if pd.isna(num_val):\n",
    "            return False\n",
    "        return min_val <= num_val <= max_val\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Compter les dates invalides par ligne et par groupe\n",
    "rows_with_all_invalid = []\n",
    "rows_with_2_groups_invalid = []\n",
    "rows_with_1_group_invalid = []\n",
    "\n",
    "for idx, row in data_cleaned.iterrows():\n",
    "    taken_invalid_count = 0\n",
    "    upload_invalid_count = 0\n",
    "    \n",
    "    # Vérifier les dates taken\n",
    "    for col in taken_cols:\n",
    "        min_val, max_val = validation_ranges[col]\n",
    "        if not is_date_valid(row[col], min_val, max_val):\n",
    "            taken_invalid_count += 1\n",
    "    \n",
    "    # Vérifier les dates upload\n",
    "    for col in upload_cols:\n",
    "        min_val, max_val = validation_ranges[col]\n",
    "        if not is_date_valid(row[col], min_val, max_val):\n",
    "            upload_invalid_count += 1\n",
    "    \n",
    "    # Compter les groupes invalides (groupe invalide = tous les champs du groupe sont invalides)\n",
    "    taken_all_invalid = taken_invalid_count == 5\n",
    "    upload_all_invalid = upload_invalid_count == 5\n",
    "    \n",
    "    # Vérifier les conditions\n",
    "    if taken_all_invalid and upload_all_invalid:\n",
    "        rows_with_all_invalid.append(idx)\n",
    "    elif (taken_all_invalid and upload_all_invalid is False and upload_invalid_count > 0) or \\\n",
    "         (upload_all_invalid and taken_all_invalid is False and taken_invalid_count > 0) or \\\n",
    "         (taken_all_invalid and upload_invalid_count == 0) or \\\n",
    "         (upload_all_invalid and taken_invalid_count == 0):\n",
    "        # Au moins 2 groupes complets invalides, mais pas les deux groupes en même temps\n",
    "        invalid_groups = sum([taken_all_invalid, upload_all_invalid])\n",
    "        if invalid_groups >= 2:\n",
    "            rows_with_2_groups_invalid.append(idx)\n",
    "    elif taken_invalid_count == 5 or upload_invalid_count == 5:\n",
    "        # Exactement 1 groupe complètement invalide\n",
    "        rows_with_1_group_invalid.append(idx)\n",
    "\n",
    "print(f\"\\nRésultats:\")\n",
    "print(f\"- Lignes avec TOUTES les dates invalides (taken ET upload): {len(rows_with_all_invalid)}\")\n",
    "if len(rows_with_all_invalid) > 0:\n",
    "    print(f\"  Indices: {rows_with_all_invalid[:10]}\")\n",
    "\n",
    "print(f\"\\n- Lignes avec 1 groupe complet invalide (soit taken SOIT upload): {len(rows_with_1_group_invalid)}\")\n",
    "if len(rows_with_1_group_invalid) > 0:\n",
    "    print(f\"  Indices: {rows_with_1_group_invalid[:10]}\")\n",
    "\n",
    "print(f\"\\nRésumé:\")\n",
    "print(f\"- Total lignes avec au moins une date invalide: {len(rows_with_all_invalid) + len(rows_with_1_group_invalid)}\")\n",
    "print(f\"- Lignes valides complètement: {len(data_cleaned) - len(rows_with_all_invalid) - len(rows_with_1_group_invalid)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
